{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fd0ad0b",
   "metadata": {},
   "source": [
    "# Baixando dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e54947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the DataLoader class from the get_data_from_db module\n",
    "from get_data_from_db import DataLoader\n",
    "\n",
    "# Initialize the DataLoader\n",
    "data_loader = DataLoader()\n",
    "\n",
    "# Get the dataset path\n",
    "path = data_loader.path\n",
    "print(f\"Dataset path: {path}\")\n",
    "\n",
    "# Get test and train data\n",
    "test_data = data_loader.get_test_data()\n",
    "train_data = data_loader.get_train_data()\n",
    "\n",
    "print(f\"Number of test images: {len(test_data)}\")\n",
    "print(f\"Number of train images: {len(train_data)}\")\n",
    "print(f\"Sample test files: {test_data[:5] if len(test_data) > 5 else test_data}\")\n",
    "print(f\"Sample train files: {train_data[:5] if len(train_data) > 5 else train_data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e597427a",
   "metadata": {},
   "source": [
    "Os arquivos já estavam separados em treino e teste"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccb9228",
   "metadata": {},
   "source": [
    "Obtendo os arquivos de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0989c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the DataLoader to get all category paths and files\n",
    "import os\n",
    "\n",
    "# Get all test categories (normal)\n",
    "test_normal_path = os.path.join(path, \"test\", \"0_normal\")\n",
    "test_normal_files = os.listdir(test_normal_path)\n",
    "\n",
    "# Get all train categories\n",
    "train_normal_path = os.path.join(path, \"train\", \"0_normal\")\n",
    "train_normal_files = os.listdir(train_normal_path)\n",
    "\n",
    "train_ulcerative_colitis_path = os.path.join(path, \"train\", \"1_ulcerative_colitis\")\n",
    "train_ulcerative_colitis_files = os.listdir(train_ulcerative_colitis_path)\n",
    "\n",
    "train_polyps_path = os.path.join(path, \"train\", \"2_polyps\")\n",
    "train_polyps_files = os.listdir(train_polyps_path)\n",
    "\n",
    "train_esophagitis_path = os.path.join(path, \"train\", \"3_esophagitis\")\n",
    "train_esophagitis_files = os.listdir(train_esophagitis_path)\n",
    "\n",
    "# Print summary of all categories\n",
    "print(\"Dataset Summary:\")\n",
    "print(f\"Test Normal: {len(test_normal_files)} images\")\n",
    "print(f\"Train Normal: {len(train_normal_files)} images\")\n",
    "print(f\"Train Ulcerative Colitis: {len(train_ulcerative_colitis_files)} images\")\n",
    "print(f\"Train Polyps: {len(train_polyps_files)} images\")\n",
    "print(f\"Train Esophagitis: {len(train_esophagitis_files)} images\")\n",
    "\n",
    "# Total counts\n",
    "total_test = len(test_normal_files)\n",
    "total_train = len(train_normal_files) + len(train_ulcerative_colitis_files) + len(train_polyps_files) + len(train_esophagitis_files)\n",
    "print(f\"\\nTotal Test Images: {total_test}\")\n",
    "print(f\"Total Train Images: {total_train}\")\n",
    "print(f\"Total Dataset: {total_test + total_train} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b245614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete dataset analysis including validation data\n",
    "import importlib\n",
    "import get_data_from_db\n",
    "importlib.reload(get_data_from_db)\n",
    "from get_data_from_db import DataLoader\n",
    "\n",
    "# Create a new DataLoader instance with enhanced features\n",
    "enhanced_loader = DataLoader()\n",
    "\n",
    "# Get all category counts including validation\n",
    "counts = enhanced_loader.get_category_counts()\n",
    "print(\"Complete Dataset Counts:\")\n",
    "for category, count in counts.items():\n",
    "    print(f\"  {category}: {count} images\")\n",
    "\n",
    "# Calculate totals by split\n",
    "test_total = counts['test_normal']\n",
    "train_total = counts['train_normal'] + counts['train_ulcerative_colitis'] + counts['train_polyps'] + counts['train_esophagitis']\n",
    "val_total = counts['val_normal'] + counts['val_ulcerative_colitis'] + counts['val_polyps'] + counts['val_esophagitis']\n",
    "total_images = test_total + train_total + val_total\n",
    "\n",
    "print(f\"\\nDataset Split Summary:\")\n",
    "print(f\"  Training: {train_total} images\")\n",
    "print(f\"  Validation: {val_total} images\")\n",
    "print(f\"  Testing: {test_total} images\")\n",
    "print(f\"  Total: {total_images} images\")\n",
    "\n",
    "# Get validation data organized by category\n",
    "validation_by_category = enhanced_loader.get_validation_data()\n",
    "print(f\"\\nValidation data categories: {list(validation_by_category.keys())}\")\n",
    "\n",
    "# Get validation data with labels\n",
    "validation_with_labels = enhanced_loader.get_validation_data_with_labels()\n",
    "print(f\"Total validation samples with labels: {len(validation_with_labels)}\")\n",
    "print(\"Sample validation data with labels:\")\n",
    "category_names = ['normal', 'ulcerative_colitis', 'polyps', 'esophagitis']\n",
    "for i in range(min(5, len(validation_with_labels))):\n",
    "    filename, label = validation_with_labels[i]\n",
    "    print(f\"  {filename} -> {category_names[label]} (label: {label})\")\n",
    "\n",
    "# Show distribution across categories\n",
    "print(f\"\\nCategory Distribution:\")\n",
    "for i, category in enumerate(category_names):\n",
    "    train_count = counts[f'train_{category}']\n",
    "    val_count = counts[f'val_{category}']\n",
    "    test_count = counts['test_normal'] if category == 'normal' else 0\n",
    "    print(f\"  {category.upper()}:\")\n",
    "    print(f\"    Train: {train_count}, Val: {val_count}, Test: {test_count}\")\n",
    "    print(f\"    Total: {train_count + val_count + test_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6862ea7",
   "metadata": {},
   "source": [
    "# Análise Completa do Dataset\n",
    "\n",
    "O dataset está organizado em três divisões:\n",
    "\n",
    "## Estrutura do Dataset:\n",
    "- **Treino (train/)**: 3.200 imagens (800 por categoria)\n",
    "- **Validação (val/)**: 2.000 imagens (500 por categoria)  \n",
    "- **Teste (test/)**: 200 imagens (apenas categoria normal)\n",
    "\n",
    "## Categorias:\n",
    "1. **Normal (0)**: Imagens normais do cólon\n",
    "2. **Ulcerative Colitis (1)**: Colite ulcerativa\n",
    "3. **Polyps (2)**: Pólipos\n",
    "4. **Esophagitis (3)**: Esofagite\n",
    "\n",
    "## Total: 5.400 imagens\n",
    "\n",
    "**Nota**: O conjunto de teste contém apenas imagens da categoria \"normal\", enquanto treino e validação contêm todas as 4 categorias balanceadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfbe173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: How to use the DataLoader for machine learning workflows\n",
    "import numpy as np\n",
    "\n",
    "# Get all data splits with labels\n",
    "train_data_with_labels = enhanced_loader.get_train_data()\n",
    "val_data_with_labels = enhanced_loader.get_validation_data_with_labels()\n",
    "test_data_files = enhanced_loader.get_test_data()  # Only normal images\n",
    "\n",
    "print(\"Data for Machine Learning:\")\n",
    "print(f\"Training samples: {len(train_data_with_labels)} (with labels)\")\n",
    "print(f\"Validation samples: {len(val_data_with_labels)} (with labels)\")\n",
    "print(f\"Test samples: {len(test_data_files)} (normal only)\")\n",
    "\n",
    "# Example: Extract labels for analysis\n",
    "train_labels = [label for _, label in train_data_with_labels]\n",
    "val_labels = [label for _, label in val_data_with_labels]\n",
    "\n",
    "print(f\"\\nLabel distribution in training:\")\n",
    "unique_labels, train_counts = np.unique(train_labels, return_counts=True)\n",
    "for label, count in zip(unique_labels, train_counts):\n",
    "    print(f\"  Label {label} ({category_names[label]}): {count} samples\")\n",
    "\n",
    "print(f\"\\nLabel distribution in validation:\")\n",
    "unique_labels, val_counts = np.unique(val_labels, return_counts=True)\n",
    "for label, count in zip(unique_labels, val_counts):\n",
    "    print(f\"  Label {label} ({category_names[label]}): {count} samples\")\n",
    "\n",
    "# Example: Get full file paths for a specific category\n",
    "normal_train_files = enhanced_loader.get_train_data_by_category()['normal']\n",
    "normal_val_files = enhanced_loader.get_validation_data()['normal']\n",
    "\n",
    "print(f\"\\nExample file paths for 'normal' category:\")\n",
    "print(f\"  Train path: {enhanced_loader.train_normal_path}\")\n",
    "print(f\"  Validation path: {enhanced_loader.validation_normal_path}\")\n",
    "print(f\"  Sample files: {normal_train_files[:3]} (train), {normal_val_files[:3]} (val)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9077bc25",
   "metadata": {},
   "source": [
    "# Modelo de Machine Learning para Classificação\n",
    "\n",
    "Agora vamos implementar um modelo de deep learning (CNN - Convolutional Neural Network) para classificar as imagens de cólon nas 4 categorias:\n",
    "\n",
    "1. **Normal (0)**\n",
    "2. **Ulcerative Colitis (1)**  \n",
    "3. **Polyps (2)**\n",
    "4. **Esophagitis (3)**\n",
    "\n",
    "O modelo será treinado usando:\n",
    "- **3.200 imagens de treino** (800 por categoria)\n",
    "- **2.000 imagens de validação** (500 por categoria)\n",
    "- **200 imagens de teste** (apenas normal - para detecção de anomalias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26c3c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "%pip install opencv-python scikit-learn\n",
    "\n",
    "# Import necessary libraries for machine learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.applications import VGG16, ResNet50\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")\n",
    "print(f\"Number of GPUs: {len(tf.config.list_physical_devices('GPU'))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35698275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample images from each category\n",
    "def show_sample_images(enhanced_loader, num_samples=2):\n",
    "    \"\"\"Display sample images from each category\"\"\"\n",
    "    \n",
    "    category_names = ['normal', 'ulcerative_colitis', 'polyps', 'esophagitis']\n",
    "    category_paths = {\n",
    "        'normal': enhanced_loader.train_normal_path,\n",
    "        'ulcerative_colitis': enhanced_loader.train_ulcerative_colitis_path,\n",
    "        'polyps': enhanced_loader.train_polyps_path,\n",
    "        'esophagitis': enhanced_loader.train_esophagitis_path\n",
    "    }\n",
    "    \n",
    "    fig, axes = plt.subplots(4, num_samples, figsize=(12, 16))\n",
    "    \n",
    "    for i, category in enumerate(category_names):\n",
    "        files = os.listdir(category_paths[category])\n",
    "        sample_files = random.sample(files, num_samples)\n",
    "        \n",
    "        for j, filename in enumerate(sample_files):\n",
    "            img_path = os.path.join(category_paths[category], filename)\n",
    "            img = load_img(img_path, target_size=(224, 224))\n",
    "            \n",
    "            axes[i, j].imshow(img)\n",
    "            axes[i, j].set_title(f'{category.upper()}\\n{filename}')\n",
    "            axes[i, j].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Show sample images\n",
    "show_sample_images(enhanced_loader, num_samples=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa2fcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data generators for training and validation\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 4\n",
    "\n",
    "# Data augmentation for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Only rescaling for validation (no augmentation)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create generators using the directory structure\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    os.path.join(enhanced_loader.path, 'train'),\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    os.path.join(enhanced_loader.path, 'val'),\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(f\"Training generator: {train_generator.samples} samples\")\n",
    "print(f\"Validation generator: {val_generator.samples} samples\")\n",
    "print(f\"Class indices: {train_generator.class_indices}\")\n",
    "print(f\"Number of classes: {train_generator.num_classes}\")\n",
    "\n",
    "# Calculate steps per epoch\n",
    "STEPS_PER_EPOCH = train_generator.samples // BATCH_SIZE\n",
    "VALIDATION_STEPS = val_generator.samples // BATCH_SIZE\n",
    "\n",
    "print(f\"Steps per epoch: {STEPS_PER_EPOCH}\")\n",
    "print(f\"Validation steps: {VALIDATION_STEPS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579d9f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CNN models\n",
    "def create_custom_cnn(input_shape=(224, 224, 3), num_classes=4):\n",
    "    \"\"\"Create a custom CNN model\"\"\"\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "        # First Conv Block\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D(2, 2),\n",
    "        \n",
    "        # Second Conv Block\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D(2, 2),\n",
    "        \n",
    "        # Third Conv Block\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D(2, 2),\n",
    "        \n",
    "        # Fourth Conv Block\n",
    "        layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D(2, 2),\n",
    "        \n",
    "        # Classifier\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def create_transfer_learning_model(input_shape=(224, 224, 3), num_classes=4):\n",
    "    \"\"\"Create a transfer learning model using VGG16\"\"\"\n",
    "    \n",
    "    # Load pre-trained VGG16 model\n",
    "    base_model = VGG16(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=input_shape\n",
    "    )\n",
    "    \n",
    "    # Freeze base model layers\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # Add custom classification head\n",
    "    model = keras.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model, base_model\n",
    "\n",
    "# Create both models\n",
    "print(\"Creating Custom CNN model...\")\n",
    "custom_model = create_custom_cnn()\n",
    "custom_model.summary()\n",
    "\n",
    "print(\"\\\\n\" + \"=\"*50)\n",
    "print(\"Creating Transfer Learning model (VGG16)...\")\n",
    "transfer_model, base_model = create_transfer_learning_model()\n",
    "transfer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f9fbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and train the transfer learning model (VGG16)\n",
    "# We'll focus on the transfer learning model as it typically performs better\n",
    "\n",
    "# Compile the model\n",
    "transfer_model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy', 'precision', 'recall']\n",
    ")\n",
    "\n",
    "# Define callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        min_lr=0.0001,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"Starting training of Transfer Learning Model (VGG16)...\")\n",
    "print(f\"Training for maximum of 20 epochs with early stopping...\")\n",
    "\n",
    "# Train the model\n",
    "EPOCHS = 10\n",
    "\n",
    "history = transfer_model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=VALIDATION_STEPS,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ad099f",
   "metadata": {},
   "source": [
    "# Avaliação e Teste do Modelo\n",
    "\n",
    "Agora vamos avaliar o desempenho do modelo treinado usando métricas detalhadas e visualizações:\n",
    "\n",
    "1. **Plotar curvas de treinamento** (loss e accuracy)\n",
    "2. **Avaliar no conjunto de validação** \n",
    "3. **Gerar matriz de confusão**\n",
    "4. **Calcular métricas detalhadas** (precision, recall, F1-score)\n",
    "5. **Testar predições** em imagens individuais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5713b824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "def plot_training_history(history):\n",
    "    \"\"\"Plot training and validation metrics\"\"\"\n",
    "    \n",
    "    # Get metrics from history\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    \n",
    "    epochs_range = range(len(acc))\n",
    "    \n",
    "    # Create subplots\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Plot accuracy\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    \n",
    "    # Plot loss\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(epochs_range, loss, label='Training Loss')\n",
    "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    \n",
    "    # Plot additional metrics if available\n",
    "    plt.subplot(1, 3, 3)\n",
    "    if 'precision' in history.history:\n",
    "        plt.plot(epochs_range, history.history['precision'], label='Training Precision')\n",
    "        plt.plot(epochs_range, history.history['val_precision'], label='Validation Precision')\n",
    "    if 'recall' in history.history:\n",
    "        plt.plot(epochs_range, history.history['recall'], label='Training Recall', linestyle='--')\n",
    "        plt.plot(epochs_range, history.history['val_recall'], label='Validation Recall', linestyle='--')\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.title('Training and Validation Metrics')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Score')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print final metrics\n",
    "    print(\"Final Training Results:\")\n",
    "    print(f\"Training Accuracy: {acc[-1]:.4f}\")\n",
    "    print(f\"Validation Accuracy: {val_acc[-1]:.4f}\")\n",
    "    print(f\"Training Loss: {loss[-1]:.4f}\")\n",
    "    print(f\"Validation Loss: {val_loss[-1]:.4f}\")\n",
    "\n",
    "# Plot the training history\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752fe8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model on validation set\n",
    "print(\"Evaluating model on validation set...\")\n",
    "\n",
    "# Get validation loss and metrics\n",
    "val_loss, val_accuracy, val_precision, val_recall = transfer_model.evaluate(\n",
    "    val_generator, \n",
    "    steps=VALIDATION_STEPS, \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(f\"\\nValidation Results:\")\n",
    "print(f\"Loss: {val_loss:.4f}\")\n",
    "print(f\"Accuracy: {val_accuracy:.4f}\")\n",
    "print(f\"Precision: {val_precision:.4f}\")\n",
    "print(f\"Recall: {val_recall:.4f}\")\n",
    "print(f\"F1-Score: {2 * (val_precision * val_recall) / (val_precision + val_recall):.4f}\")\n",
    "\n",
    "# Generate predictions for confusion matrix\n",
    "print(\"\\nGenerating predictions for confusion matrix...\")\n",
    "\n",
    "# Reset the validation generator to ensure we get all samples in order\n",
    "val_generator.reset()\n",
    "\n",
    "# Get predictions\n",
    "predictions = transfer_model.predict(val_generator, steps=VALIDATION_STEPS, verbose=1)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Get true labels\n",
    "true_classes = val_generator.classes[:len(predicted_classes)]\n",
    "\n",
    "# Get class names\n",
    "class_names = list(val_generator.class_indices.keys())\n",
    "print(f\"Classes: {class_names}\")\n",
    "print(f\"Number of predictions: {len(predicted_classes)}\")\n",
    "print(f\"Number of true labels: {len(true_classes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2993d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and plot confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_confusion_matrix(true_labels, predicted_labels, class_names, title=\"Confusion Matrix\"):\n",
    "    \"\"\"Plot a detailed confusion matrix\"\"\"\n",
    "    \n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(true_labels, predicted_labels)\n",
    "    \n",
    "    # Create figure with subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Plot raw confusion matrix\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=class_names, yticklabels=class_names, ax=ax1)\n",
    "    ax1.set_title(f'{title} - Raw Counts')\n",
    "    ax1.set_xlabel('Predicted')\n",
    "    ax1.set_ylabel('Actual')\n",
    "    \n",
    "    # Plot normalized confusion matrix (percentages)\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    sns.heatmap(cm_normalized, annot=True, fmt='.2%', cmap='Blues',\n",
    "                xticklabels=class_names, yticklabels=class_names, ax=ax2)\n",
    "    ax2.set_title(f'{title} - Normalized (%)')\n",
    "    ax2.set_xlabel('Predicted')\n",
    "    ax2.set_ylabel('Actual')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return cm, cm_normalized\n",
    "\n",
    "# Generate confusion matrix\n",
    "print(\"Creating Confusion Matrix...\")\n",
    "cm, cm_norm = plot_confusion_matrix(true_classes, predicted_classes, class_names, \n",
    "                                   \"Validation Set Confusion Matrix\")\n",
    "\n",
    "# Print detailed metrics\n",
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(classification_report(true_classes, predicted_classes, target_names=class_names, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6befd1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze performance per category\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "def analyze_per_category_performance(true_labels, predicted_labels, class_names):\n",
    "    \"\"\"Analyze model performance for each category\"\"\"\n",
    "    \n",
    "    print(\"Performance Analysis by Category:\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Calculate metrics for each class\n",
    "    precision_per_class = precision_score(true_labels, predicted_labels, average=None)\n",
    "    recall_per_class = recall_score(true_labels, predicted_labels, average=None)\n",
    "    f1_per_class = f1_score(true_labels, predicted_labels, average=None)\n",
    "    \n",
    "    # Create a summary table\n",
    "    performance_data = []\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        # Count correct and total predictions for this class\n",
    "        class_mask = (true_labels == i)\n",
    "        total_actual = np.sum(class_mask)\n",
    "        correct_predictions = np.sum((true_labels == i) & (predicted_labels == i))\n",
    "        \n",
    "        performance_data.append({\n",
    "            'Category': class_name.upper(),\n",
    "            'Precision': f\"{precision_per_class[i]:.4f}\",\n",
    "            'Recall': f\"{recall_per_class[i]:.4f}\",\n",
    "            'F1-Score': f\"{f1_per_class[i]:.4f}\",\n",
    "            'Correct': correct_predictions,\n",
    "            'Total': total_actual,\n",
    "            'Accuracy': f\"{correct_predictions/total_actual:.4f}\" if total_actual > 0 else \"N/A\"\n",
    "        })\n",
    "        \n",
    "        print(f\"{class_name.upper():20} | \"\n",
    "              f\"Precision: {precision_per_class[i]:.4f} | \"\n",
    "              f\"Recall: {recall_per_class[i]:.4f} | \"\n",
    "              f\"F1: {f1_per_class[i]:.4f} | \"\n",
    "              f\"Correct: {correct_predictions:3d}/{total_actual:3d}\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Overall metrics\n",
    "    overall_accuracy = np.sum(true_labels == predicted_labels) / len(true_labels)\n",
    "    avg_precision = np.mean(precision_per_class)\n",
    "    avg_recall = np.mean(recall_per_class)\n",
    "    avg_f1 = np.mean(f1_per_class)\n",
    "    \n",
    "    print(f\"OVERALL METRICS:\")\n",
    "    print(f\"Accuracy:  {overall_accuracy:.4f}\")\n",
    "    print(f\"Avg Precision: {avg_precision:.4f}\")\n",
    "    print(f\"Avg Recall:    {avg_recall:.4f}\")\n",
    "    print(f\"Avg F1-Score:  {avg_f1:.4f}\")\n",
    "    \n",
    "    return performance_data\n",
    "\n",
    "# Analyze performance\n",
    "performance_results = analyze_per_category_performance(true_classes, predicted_classes, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6bb6e2",
   "metadata": {},
   "source": [
    "# Preparação para Validação Cruzada\n",
    "\n",
    "Agora vamos juntar todos os dados das classes correspondentes (treino, validação e teste) em um conjunto único para depois redistribuí-los em K-fold cross validation.\n",
    "\n",
    "**Estratégia**:\n",
    "1. **Juntar todas as imagens por categoria** (normal, ulcerative_colitis, polyps, esophagitis)\n",
    "2. **Criar um dataset unificado** com todas as imagens e seus labels\n",
    "3. **Preparar para K-fold** onde cada fold terá uma distribuição balanceada das classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37afc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all image paths from all splits (train, val, test) by category\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "def collect_all_images_by_category(enhanced_loader):\n",
    "    \"\"\"Collect all image paths from train, val, and test sets by category\"\"\"\n",
    "    \n",
    "    # Initialize dictionary to store all images by category\n",
    "    all_images_by_category = {\n",
    "        'normal': [],\n",
    "        'ulcerative_colitis': [],\n",
    "        'polyps': [],\n",
    "        'esophagitis': []\n",
    "    }\n",
    "    \n",
    "    # Category mapping for folder names\n",
    "    category_folders = {\n",
    "        'normal': '0_normal',\n",
    "        'ulcerative_colitis': '1_ulcerative_colitis', \n",
    "        'polyps': '2_polyps',\n",
    "        'esophagitis': '3_esophagitis'\n",
    "    }\n",
    "    \n",
    "    # Collect from train folder\n",
    "    print(\"Collecting images from TRAIN folder...\")\n",
    "    train_path = os.path.join(enhanced_loader.path, 'train')\n",
    "    for category, folder_name in category_folders.items():\n",
    "        folder_path = os.path.join(train_path, folder_name)\n",
    "        if os.path.exists(folder_path):\n",
    "            # Get all image files (jpg, jpeg, png)\n",
    "            image_files = []\n",
    "            for ext in ['*.jpg', '*.jpeg', '*.png', '*.JPG', '*.JPEG', '*.PNG']:\n",
    "                image_files.extend(glob.glob(os.path.join(folder_path, ext)))\n",
    "            all_images_by_category[category].extend(image_files)\n",
    "            print(f\"  {category}: {len(image_files)} images from train\")\n",
    "    \n",
    "    # Collect from validation folder\n",
    "    print(\"\\\\nCollecting images from VALIDATION folder...\")\n",
    "    val_path = os.path.join(enhanced_loader.path, 'val')\n",
    "    for category, folder_name in category_folders.items():\n",
    "        folder_path = os.path.join(val_path, folder_name)\n",
    "        if os.path.exists(folder_path):\n",
    "            image_files = []\n",
    "            for ext in ['*.jpg', '*.jpeg', '*.png', '*.JPG', '*.JPEG', '*.PNG']:\n",
    "                image_files.extend(glob.glob(os.path.join(folder_path, ext)))\n",
    "            all_images_by_category[category].extend(image_files)\n",
    "            print(f\"  {category}: {len(image_files)} images from validation\")\n",
    "    \n",
    "    # Collect from test folder (only normal)\n",
    "    print(\"\\\\nCollecting images from TEST folder...\")\n",
    "    test_path = os.path.join(enhanced_loader.path, 'test')\n",
    "    test_normal_path = os.path.join(test_path, '0_normal')\n",
    "    if os.path.exists(test_normal_path):\n",
    "        image_files = []\n",
    "        for ext in ['*.jpg', '*.jpeg', '*.png', '*.JPG', '*.JPEG', '*.PNG']:\n",
    "            image_files.extend(glob.glob(os.path.join(test_normal_path, ext)))\n",
    "        all_images_by_category['normal'].extend(image_files)\n",
    "        print(f\"  normal: {len(image_files)} images from test\")\n",
    "    \n",
    "    return all_images_by_category\n",
    "\n",
    "# Collect all images\n",
    "print(\"=\"*60)\n",
    "print(\"COLLECTING ALL IMAGES BY CATEGORY\")\n",
    "print(\"=\"*60)\n",
    "all_images = collect_all_images_by_category(enhanced_loader)\n",
    "\n",
    "# Print summary\n",
    "print(\"\\\\n\" + \"=\"*60)\n",
    "print(\"TOTAL IMAGES BY CATEGORY:\")\n",
    "print(\"=\"*60)\n",
    "total_all_images = 0\n",
    "for category, images in all_images.items():\n",
    "    print(f\"{category.upper():20}: {len(images):4d} images\")\n",
    "    total_all_images += len(images)\n",
    "\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'TOTAL':20}: {total_all_images:4d} images\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b6994a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create unified dataset with all images and labels\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "def create_unified_dataset(all_images_by_category):\n",
    "    \"\"\"Create a unified dataset with all images and their corresponding labels\"\"\"\n",
    "    \n",
    "    # Category to label mapping\n",
    "    category_to_label = {\n",
    "        'normal': 0,\n",
    "        'ulcerative_colitis': 1,\n",
    "        'polyps': 2,\n",
    "        'esophagitis': 3\n",
    "    }\n",
    "    \n",
    "    # Create lists for all images and labels\n",
    "    all_image_paths = []\n",
    "    all_labels = []\n",
    "    all_categories = []\n",
    "    \n",
    "    print(\"Creating unified dataset...\")\n",
    "    for category, image_paths in all_images_by_category.items():\n",
    "        label = category_to_label[category]\n",
    "        \n",
    "        # Add all images from this category\n",
    "        all_image_paths.extend(image_paths)\n",
    "        all_labels.extend([label] * len(image_paths))\n",
    "        all_categories.extend([category] * len(image_paths))\n",
    "        \n",
    "        print(f\"Added {len(image_paths)} {category} images with label {label}\")\n",
    "    \n",
    "    # Create DataFrame\n",
    "    unified_df = pd.DataFrame({\n",
    "        'image_path': all_image_paths,\n",
    "        'label': all_labels,\n",
    "        'category': all_categories\n",
    "    })\n",
    "    \n",
    "    # Shuffle the dataset\n",
    "    unified_df = shuffle(unified_df, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    return unified_df\n",
    "\n",
    "# Create unified dataset\n",
    "unified_dataset = create_unified_dataset(all_images)\n",
    "\n",
    "print(\"\\\\n\" + \"=\"*60)\n",
    "print(\"UNIFIED DATASET CREATED\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total samples: {len(unified_dataset)}\")\n",
    "print(f\"Features: {list(unified_dataset.columns)}\")\n",
    "\n",
    "# Show distribution\n",
    "print(\"\\\\nLabel distribution in unified dataset:\")\n",
    "label_counts = unified_dataset['label'].value_counts().sort_index()\n",
    "category_names = ['normal', 'ulcerative_colitis', 'polyps', 'esophagitis']\n",
    "\n",
    "for label, count in label_counts.items():\n",
    "    category = category_names[label]\n",
    "    percentage = (count / len(unified_dataset)) * 100\n",
    "    print(f\"  Label {label} ({category:18}): {count:4d} samples ({percentage:5.1f}%)\")\n",
    "\n",
    "# Show first few samples\n",
    "print(f\"\\\\nFirst 5 samples:\")\n",
    "for i in range(min(5, len(unified_dataset))):\n",
    "    row = unified_dataset.iloc[i]\n",
    "    filename = os.path.basename(row['image_path'])\n",
    "    print(f\"  {i+1}. {filename:30} -> Label: {row['label']} ({row['category']})\")\n",
    "\n",
    "print(\"\\\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099b436c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify data integrity and prepare for K-fold cross validation\n",
    "from collections import Counter\n",
    "\n",
    "def verify_data_integrity(unified_df):\n",
    "    \"\"\"Verify that all image files exist and are accessible\"\"\"\n",
    "    \n",
    "    print(\"Verifying data integrity...\")\n",
    "    \n",
    "    # Check if all files exist\n",
    "    missing_files = []\n",
    "    accessible_files = 0\n",
    "    \n",
    "    for i, row in unified_df.iterrows():\n",
    "        if os.path.exists(row['image_path']):\n",
    "            accessible_files += 1\n",
    "        else:\n",
    "            missing_files.append(row['image_path'])\n",
    "    \n",
    "    print(f\"Total files: {len(unified_df)}\")\n",
    "    print(f\"Accessible files: {accessible_files}\")\n",
    "    print(f\"Missing files: {len(missing_files)}\")\n",
    "    \n",
    "    if missing_files:\n",
    "        print(\"\\\\nMissing files:\")\n",
    "        for file_path in missing_files[:10]:  # Show first 10\n",
    "            print(f\"  {file_path}\")\n",
    "        if len(missing_files) > 10:\n",
    "            print(f\"  ... and {len(missing_files) - 10} more\")\n",
    "    \n",
    "    return len(missing_files) == 0\n",
    "\n",
    "# Verify integrity\n",
    "print(\"=\"*60)\n",
    "print(\"DATA INTEGRITY VERIFICATION\")\n",
    "print(\"=\"*60)\n",
    "data_is_valid = verify_data_integrity(unified_dataset)\n",
    "\n",
    "if data_is_valid:\n",
    "    print(\"✅ All data files are accessible!\")\n",
    "else:\n",
    "    print(\"❌ Some data files are missing!\")\n",
    "\n",
    "# Show detailed statistics\n",
    "print(\"\\\\n\" + \"=\"*60)\n",
    "print(\"DETAILED DATASET STATISTICS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Overall statistics\n",
    "print(f\"Dataset shape: {unified_dataset.shape}\")\n",
    "print(f\"Total samples: {len(unified_dataset)}\")\n",
    "print(f\"Number of features: {len(unified_dataset.columns)}\")\n",
    "\n",
    "# Class balance analysis\n",
    "print(\"\\\\nClass distribution analysis:\")\n",
    "for label in range(4):\n",
    "    subset = unified_dataset[unified_dataset['label'] == label]\n",
    "    category = category_names[label]\n",
    "    count = len(subset)\n",
    "    percentage = (count / len(unified_dataset)) * 100\n",
    "    \n",
    "    print(f\"  Class {label} ({category:18}):\")\n",
    "    print(f\"    Count: {count:4d} samples ({percentage:5.1f}%)\")\n",
    "    \n",
    "    # Show some example file paths\n",
    "    sample_paths = subset['image_path'].head(3).apply(lambda x: os.path.basename(x)).tolist()\n",
    "    print(f\"    Examples: {', '.join(sample_paths)}\")\n",
    "\n",
    "# Check for balanced dataset\n",
    "label_counts = unified_dataset['label'].value_counts().sort_index()\n",
    "min_count = label_counts.min()\n",
    "max_count = label_counts.max()\n",
    "balance_ratio = min_count / max_count\n",
    "\n",
    "print(f\"\\\\nClass balance analysis:\")\n",
    "print(f\"  Minimum class size: {min_count}\")\n",
    "print(f\"  Maximum class size: {max_count}\")\n",
    "print(f\"  Balance ratio: {balance_ratio:.3f}\")\n",
    "\n",
    "if balance_ratio >= 0.8:\n",
    "    print(\"  ✅ Dataset is well balanced\")\n",
    "elif balance_ratio >= 0.6:\n",
    "    print(\"  ⚠️ Dataset has moderate imbalance\")\n",
    "else:\n",
    "    print(\"  ❌ Dataset is highly imbalanced\")\n",
    "\n",
    "print(\"\\\\n\" + \"=\"*60)\n",
    "print(\"READY FOR K-FOLD CROSS VALIDATION!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9545e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup K-fold Cross Validation\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def setup_kfold_cv(unified_df, k=5, random_state=42):\n",
    "    \"\"\"Setup stratified K-fold cross validation\"\"\"\n",
    "    \n",
    "    print(f\"Setting up {k}-Fold Cross Validation...\")\n",
    "    \n",
    "    # Extract features and labels\n",
    "    X = unified_df['image_path'].values  # Image paths as features\n",
    "    y = unified_df['label'].values       # Labels\n",
    "    \n",
    "    # Create stratified K-fold\n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    # Store fold information\n",
    "    fold_info = []\n",
    "    \n",
    "    print(f\"\\\\nCreating {k} stratified folds...\")\n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        # Get train and validation data for this fold\n",
    "        X_train_fold = X[train_idx]\n",
    "        X_val_fold = X[val_idx]\n",
    "        y_train_fold = y[train_idx]\n",
    "        y_val_fold = y[val_idx]\n",
    "        \n",
    "        # Calculate class distribution for this fold\n",
    "        train_dist = Counter(y_train_fold)\n",
    "        val_dist = Counter(y_val_fold)\n",
    "        \n",
    "        fold_data = {\n",
    "            'fold': fold_idx + 1,\n",
    "            'train_indices': train_idx,\n",
    "            'val_indices': val_idx,\n",
    "            'train_paths': X_train_fold,\n",
    "            'val_paths': X_val_fold,\n",
    "            'train_labels': y_train_fold,\n",
    "            'val_labels': y_val_fold,\n",
    "            'train_distribution': train_dist,\n",
    "            'val_distribution': val_dist,\n",
    "            'train_size': len(train_idx),\n",
    "            'val_size': len(val_idx)\n",
    "        }\n",
    "        \n",
    "        fold_info.append(fold_data)\n",
    "        \n",
    "        print(f\"\\\\n  Fold {fold_idx + 1}:\")\n",
    "        print(f\"    Train size: {len(train_idx):4d} samples\")\n",
    "        print(f\"    Val size:   {len(val_idx):4d} samples\")\n",
    "        print(f\"    Train distribution: {dict(train_dist)}\")\n",
    "        print(f\"    Val distribution:   {dict(val_dist)}\")\n",
    "    \n",
    "    return fold_info, skf\n",
    "\n",
    "# Setup 5-fold cross validation\n",
    "k_folds = 5\n",
    "print(\"=\"*70)\n",
    "print(\"K-FOLD CROSS VALIDATION SETUP\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "fold_information, stratified_kfold = setup_kfold_cv(unified_dataset, k=k_folds)\n",
    "\n",
    "# Visualize fold distributions\n",
    "def plot_fold_distributions(fold_info):\n",
    "    \"\"\"Plot class distributions across folds\"\"\"\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Prepare data for plotting\n",
    "    folds = [f\"Fold {f['fold']}\" for f in fold_info]\n",
    "    categories = ['Normal', 'Ulcerative Colitis', 'Polyps', 'Esophagitis']\n",
    "    \n",
    "    # Train distributions\n",
    "    train_data = []\n",
    "    for cat_idx in range(4):\n",
    "        train_counts = [f['train_distribution'][cat_idx] for f in fold_info]\n",
    "        train_data.append(train_counts)\n",
    "    \n",
    "    # Validation distributions  \n",
    "    val_data = []\n",
    "    for cat_idx in range(4):\n",
    "        val_counts = [f['val_distribution'][cat_idx] for f in fold_info]\n",
    "        val_data.append(val_counts)\n",
    "    \n",
    "    # Plot train distributions\n",
    "    x = range(len(folds))\n",
    "    width = 0.2\n",
    "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']\n",
    "    \n",
    "    for i, (category, counts) in enumerate(zip(categories, train_data)):\n",
    "        ax1.bar([xi + i*width for xi in x], counts, width, label=category, color=colors[i], alpha=0.8)\n",
    "    \n",
    "    ax1.set_xlabel('Folds')\n",
    "    ax1.set_ylabel('Number of Samples')\n",
    "    ax1.set_title('Training Set Distribution Across Folds')\n",
    "    ax1.set_xticks([xi + width*1.5 for xi in x])\n",
    "    ax1.set_xticklabels(folds)\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot validation distributions\n",
    "    for i, (category, counts) in enumerate(zip(categories, val_data)):\n",
    "        ax2.bar([xi + i*width for xi in x], counts, width, label=category, color=colors[i], alpha=0.8)\n",
    "    \n",
    "    ax2.set_xlabel('Folds')\n",
    "    ax2.set_ylabel('Number of Samples')\n",
    "    ax2.set_title('Validation Set Distribution Across Folds')\n",
    "    ax2.set_xticks([xi + width*1.5 for xi in x])\n",
    "    ax2.set_xticklabels(folds)\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot distributions\n",
    "print(\"\\\\nVisualizing fold distributions...\")\n",
    "plot_fold_distributions(fold_information)\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\\\n\" + \"=\"*70)\n",
    "print(\"CROSS VALIDATION SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Number of folds: {k_folds}\")\n",
    "print(f\"Total samples: {len(unified_dataset)}\")\n",
    "print(f\"Average train size per fold: {fold_information[0]['train_size']}\")\n",
    "print(f\"Average validation size per fold: {fold_information[0]['val_size']}\")\n",
    "print(f\"Train/Val split ratio: {fold_information[0]['train_size']/(fold_information[0]['train_size']+fold_information[0]['val_size']):.1%}/{fold_information[0]['val_size']/(fold_information[0]['train_size']+fold_information[0]['val_size']):.1%}\")\n",
    "\n",
    "print(\"\\\\n✅ Dataset successfully unified and prepared for K-fold cross validation!\")\n",
    "print(\"\\\\n📊 You now have all images from train, validation, and test sets\")\n",
    "print(\"   combined into a single dataset ready for redistribution.\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac21ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save unified dataset and fold information for future use\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "def save_kfold_data(unified_df, fold_info, base_path=None):\n",
    "    \"\"\"Save the unified dataset and K-fold information\"\"\"\n",
    "    \n",
    "    if base_path is None:\n",
    "        base_path = os.getcwd()\n",
    "    \n",
    "    # Create output directory\n",
    "    output_dir = os.path.join(base_path, 'cross_validation_data')\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Save unified dataset as CSV\n",
    "    csv_path = os.path.join(output_dir, 'unified_dataset.csv')\n",
    "    unified_df.to_csv(csv_path, index=False)\n",
    "    print(f\"✅ Unified dataset saved to: {csv_path}\")\n",
    "    \n",
    "    # Save unified dataset as pickle (preserves data types)\n",
    "    pickle_path = os.path.join(output_dir, 'unified_dataset.pkl')\n",
    "    unified_df.to_pickle(pickle_path)\n",
    "    print(f\"✅ Unified dataset (pickle) saved to: {pickle_path}\")\n",
    "    \n",
    "    # Prepare fold information for JSON serialization\n",
    "    fold_info_serializable = []\n",
    "    for fold in fold_info:\n",
    "        # Convert numpy int64 keys to regular int for JSON compatibility\n",
    "        train_dist = {int(k): int(v) for k, v in fold['train_distribution'].items()}\n",
    "        val_dist = {int(k): int(v) for k, v in fold['val_distribution'].items()}\n",
    "        \n",
    "        fold_serializable = {\n",
    "            'fold': int(fold['fold']),\n",
    "            'train_indices': fold['train_indices'].tolist(),\n",
    "            'val_indices': fold['val_indices'].tolist(),\n",
    "            'train_size': int(fold['train_size']),\n",
    "            'val_size': int(fold['val_size']),\n",
    "            'train_distribution': train_dist,\n",
    "            'val_distribution': val_dist\n",
    "        }\n",
    "        fold_info_serializable.append(fold_serializable)\n",
    "    \n",
    "    # Save fold information as JSON\n",
    "    json_path = os.path.join(output_dir, 'kfold_info.json')\n",
    "    with open(json_path, 'w') as f:\n",
    "        json.dump({\n",
    "            'k_folds': int(len(fold_info)),\n",
    "            'total_samples': int(len(unified_df)),\n",
    "            'fold_information': fold_info_serializable\n",
    "        }, f, indent=2)\n",
    "    print(f\"✅ K-fold information saved to: {json_path}\")\n",
    "    \n",
    "    # Save fold information as pickle (preserves numpy arrays)\n",
    "    fold_pickle_path = os.path.join(output_dir, 'kfold_info.pkl')\n",
    "    with open(fold_pickle_path, 'wb') as f:\n",
    "        pickle.dump(fold_info, f)\n",
    "    print(f\"✅ K-fold information (pickle) saved to: {fold_pickle_path}\")\n",
    "    \n",
    "    # Create a summary file\n",
    "    summary_path = os.path.join(output_dir, 'dataset_summary.txt')\n",
    "    with open(summary_path, 'w') as f:\n",
    "        f.write(\"UNIFIED DATASET SUMMARY\\\\n\")\n",
    "        f.write(\"=\"*50 + \"\\\\n\")\n",
    "        f.write(f\"Creation date: {pd.Timestamp.now()}\\\\n\")\n",
    "        f.write(f\"Total samples: {len(unified_df)}\\\\n\")\n",
    "        f.write(f\"Number of classes: {len(unified_df['label'].unique())}\\\\n\")\n",
    "        f.write(f\"K-fold splits: {len(fold_info)}\\\\n\")\n",
    "        f.write(\"\\\\n\")\n",
    "        \n",
    "        f.write(\"CLASS DISTRIBUTION:\\\\n\")\n",
    "        f.write(\"-\" * 30 + \"\\\\n\")\n",
    "        for label in range(4):\n",
    "            count = len(unified_df[unified_df['label'] == label])\n",
    "            percentage = (count / len(unified_df)) * 100\n",
    "            category = ['normal', 'ulcerative_colitis', 'polyps', 'esophagitis'][label]\n",
    "            f.write(f\"Class {label} ({category:18}): {count:4d} ({percentage:5.1f}%)\\\\n\")\n",
    "        \n",
    "        f.write(\"\\\\n\")\n",
    "        f.write(\"FOLD INFORMATION:\\\\n\")\n",
    "        f.write(\"-\" * 30 + \"\\\\n\")\n",
    "        for fold in fold_info:\n",
    "            f.write(f\"Fold {fold['fold']}: {fold['train_size']} train, {fold['val_size']} val\\\\n\")\n",
    "    \n",
    "    print(f\"✅ Dataset summary saved to: {summary_path}\")\n",
    "    \n",
    "    return output_dir\n",
    "\n",
    "# Save all data\n",
    "print(\"=\"*70)\n",
    "print(\"SAVING UNIFIED DATASET AND K-FOLD INFORMATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "output_directory = save_kfold_data(unified_dataset, fold_information)\n",
    "\n",
    "print(f\"\\\\n📁 All files saved to: {output_directory}\")\n",
    "\n",
    "# Show what was created\n",
    "print(\"\\\\n📋 Created files:\")\n",
    "for file in os.listdir(output_directory):\n",
    "    file_path = os.path.join(output_directory, file)\n",
    "    file_size = os.path.getsize(file_path) / (1024*1024)  # Size in MB\n",
    "    print(f\"  • {file:25} ({file_size:.2f} MB)\")\n",
    "\n",
    "print(\"\\\\n\" + \"=\"*70)\n",
    "print(\"🎉 DATASET UNIFICATION COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\\\n✅ What was accomplished:\")\n",
    "print(\"   • Combined all images from train, validation, and test sets\")\n",
    "print(\"   • Created unified dataset with proper labels\")\n",
    "print(\"   • Setup stratified 5-fold cross validation\")\n",
    "print(\"   • Verified data integrity\")\n",
    "print(\"   • Saved all data for future use\")\n",
    "print(\"\\\\n🚀 You're now ready to:\")\n",
    "print(\"   • Run K-fold cross validation experiments\")\n",
    "print(\"   • Compare model performance across folds\")\n",
    "print(\"   • Get more robust performance estimates\")\n",
    "print(\"   • Ensure your model generalizes well\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fff185",
   "metadata": {},
   "source": [
    "# Validação Cruzada Estratificada - Implementação\n",
    "\n",
    "Agora vamos implementar a validação cruzada estratificada usando os dados unificados:\n",
    "\n",
    "## Estratégia:\n",
    "1. **Treinar o modelo VGG16** em cada um dos 5 folds\n",
    "2. **Avaliar métricas** para cada fold (accuracy, precision, recall, F1-score)\n",
    "3. **Coletar resultados** de todos os folds\n",
    "4. **Calcular estatísticas finais** (média, desvio padrão)\n",
    "5. **Comparar performance** entre folds para validar robustez\n",
    "\n",
    "## Benefícios:\n",
    "- **Estimativa mais robusta** da performance do modelo\n",
    "- **Redução do overfitting** aos dados de validação\n",
    "- **Melhor confiança** nos resultados\n",
    "- **Identificação de variabilidade** na performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312a9ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom data generators for cross-validation\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tempfile\n",
    "import shutil\n",
    "\n",
    "def create_fold_generators(fold_data, unified_df, img_size=224, batch_size=32):\n",
    "    \"\"\"Create train and validation generators for a specific fold\"\"\"\n",
    "    \n",
    "    # Get indices for this fold\n",
    "    train_indices = fold_data['train_indices']\n",
    "    val_indices = fold_data['val_indices']\n",
    "    \n",
    "    # Get data for this fold\n",
    "    train_paths = unified_df.iloc[train_indices]['image_path'].values\n",
    "    train_labels = unified_df.iloc[train_indices]['label'].values\n",
    "    val_paths = unified_df.iloc[val_indices]['image_path'].values\n",
    "    val_labels = unified_df.iloc[val_indices]['label'].values\n",
    "    \n",
    "    print(f\"Fold {fold_data['fold']}:\")\n",
    "    print(f\"  Train samples: {len(train_paths)}\")\n",
    "    print(f\"  Val samples: {len(val_paths)}\")\n",
    "    \n",
    "    # Create data generators\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=False,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    \n",
    "    val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    # Create custom generator class\n",
    "    class CustomGenerator(tf.keras.utils.Sequence):\n",
    "        def __init__(self, paths, labels, datagen, batch_size, img_size, shuffle=True):\n",
    "            self.paths = paths\n",
    "            self.labels = labels\n",
    "            self.datagen = datagen\n",
    "            self.batch_size = batch_size\n",
    "            self.img_size = img_size\n",
    "            self.shuffle = shuffle\n",
    "            self.indices = np.arange(len(self.paths))\n",
    "            if self.shuffle:\n",
    "                np.random.shuffle(self.indices)\n",
    "        \n",
    "        def __len__(self):\n",
    "            return len(self.paths) // self.batch_size\n",
    "        \n",
    "        def __getitem__(self, idx):\n",
    "            batch_indices = self.indices[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "            batch_paths = self.paths[batch_indices]\n",
    "            batch_labels = self.labels[batch_indices]\n",
    "            \n",
    "            # Load and preprocess images\n",
    "            batch_images = []\n",
    "            for path in batch_paths:\n",
    "                img = load_img(path, target_size=(self.img_size, self.img_size))\n",
    "                img_array = img_to_array(img)\n",
    "                # Apply data augmentation\n",
    "                img_array = self.datagen.random_transform(img_array)\n",
    "                img_array = self.datagen.standardize(img_array)\n",
    "                batch_images.append(img_array)\n",
    "            \n",
    "            batch_images = np.array(batch_images)\n",
    "            batch_labels_categorical = to_categorical(batch_labels, num_classes=4)\n",
    "            \n",
    "            return batch_images, batch_labels_categorical\n",
    "        \n",
    "        def on_epoch_end(self):\n",
    "            if self.shuffle:\n",
    "                np.random.shuffle(self.indices)\n",
    "    \n",
    "    # Create generators\n",
    "    train_gen = CustomGenerator(train_paths, train_labels, train_datagen, batch_size, img_size, shuffle=True)\n",
    "    val_gen = CustomGenerator(val_paths, val_labels, val_datagen, batch_size, img_size, shuffle=False)\n",
    "    \n",
    "    return train_gen, val_gen\n",
    "\n",
    "# Test generator creation with first fold\n",
    "print(\"Testing generator creation...\")\n",
    "test_train_gen, test_val_gen = create_fold_generators(fold_information[0], unified_dataset)\n",
    "print(\"✅ Generators created successfully!\")\n",
    "print(f\"Train batches per epoch: {len(test_train_gen)}\")\n",
    "print(f\"Val batches per epoch: {len(test_val_gen)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4135a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement K-Fold Cross Validation Training\n",
    "import time\n",
    "from tensorflow.keras.models import clone_model\n",
    "\n",
    "def run_cross_validation(fold_info_list, unified_df, epochs=8, verbose=1):\n",
    "    \"\"\"Run complete k-fold cross validation\"\"\"\n",
    "    \n",
    "    # Store results for each fold\n",
    "    cv_results = {\n",
    "        'fold_metrics': [],\n",
    "        'fold_histories': [],\n",
    "        'fold_models': [],\n",
    "        'training_times': []\n",
    "    }\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"STARTING K-FOLD CROSS VALIDATION\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Number of folds: {len(fold_info_list)}\")\n",
    "    print(f\"Epochs per fold: {epochs}\")\n",
    "    print(f\"Total training sessions: {len(fold_info_list)}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    for i, fold_data in enumerate(fold_info_list):\n",
    "        fold_num = fold_data['fold']\n",
    "        print(f\"\\\\n{'='*20} FOLD {fold_num}/{len(fold_info_list)} {'='*20}\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Create generators for this fold\n",
    "        print(\"Creating data generators...\")\n",
    "        train_gen, val_gen = create_fold_generators(fold_data, unified_df, \n",
    "                                                   img_size=224, batch_size=32)\n",
    "        \n",
    "        # Create a fresh model for this fold\n",
    "        print(\"Creating fresh model...\")\n",
    "        fold_model, fold_base_model = create_transfer_learning_model()\n",
    "        \n",
    "        # Compile model\n",
    "        fold_model.compile(\n",
    "            optimizer=Adam(learning_rate=0.001),\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy', 'precision', 'recall']\n",
    "        )\n",
    "        \n",
    "        # Define callbacks\n",
    "        fold_callbacks = [\n",
    "            EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                patience=3,\n",
    "                restore_best_weights=True,\n",
    "                verbose=0\n",
    "            ),\n",
    "            ReduceLROnPlateau(\n",
    "                monitor='val_loss',\n",
    "                factor=0.5,\n",
    "                patience=2,\n",
    "                min_lr=0.0001,\n",
    "                verbose=0\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        # Calculate steps\n",
    "        steps_per_epoch = len(train_gen)\n",
    "        validation_steps = len(val_gen)\n",
    "        \n",
    "        print(f\"Training fold {fold_num}...\")\n",
    "        print(f\"  Steps per epoch: {steps_per_epoch}\")\n",
    "        print(f\"  Validation steps: {validation_steps}\")\n",
    "        \n",
    "        # Train the model\n",
    "        history = fold_model.fit(\n",
    "            train_gen,\n",
    "            steps_per_epoch=steps_per_epoch,\n",
    "            epochs=epochs,\n",
    "            validation_data=val_gen,\n",
    "            validation_steps=validation_steps,\n",
    "            callbacks=fold_callbacks,\n",
    "            verbose=verbose\n",
    "        )\n",
    "        \n",
    "        # Evaluate on validation set\n",
    "        print(f\"Evaluating fold {fold_num}...\")\n",
    "        val_metrics = fold_model.evaluate(val_gen, steps=validation_steps, verbose=0)\n",
    "        \n",
    "        # Store results\n",
    "        fold_result = {\n",
    "            'fold': fold_num,\n",
    "            'val_loss': val_metrics[0],\n",
    "            'val_accuracy': val_metrics[1],\n",
    "            'val_precision': val_metrics[2],\n",
    "            'val_recall': val_metrics[3],\n",
    "            'val_f1_score': 2 * (val_metrics[2] * val_metrics[3]) / (val_metrics[2] + val_metrics[3]),\n",
    "            'epochs_trained': len(history.history['loss']),\n",
    "            'best_val_loss': min(history.history['val_loss']),\n",
    "            'best_val_accuracy': max(history.history['val_accuracy'])\n",
    "        }\n",
    "        \n",
    "        training_time = time.time() - start_time\n",
    "        \n",
    "        cv_results['fold_metrics'].append(fold_result)\n",
    "        cv_results['fold_histories'].append(history.history)\n",
    "        cv_results['fold_models'].append(fold_model)\n",
    "        cv_results['training_times'].append(training_time)\n",
    "        \n",
    "        print(f\"Fold {fold_num} Results:\")\n",
    "        print(f\"  Validation Accuracy: {fold_result['val_accuracy']:.4f}\")\n",
    "        print(f\"  Validation Loss: {fold_result['val_loss']:.4f}\")\n",
    "        print(f\"  Validation Precision: {fold_result['val_precision']:.4f}\")\n",
    "        print(f\"  Validation Recall: {fold_result['val_recall']:.4f}\")\n",
    "        print(f\"  Validation F1-Score: {fold_result['val_f1_score']:.4f}\")\n",
    "        print(f\"  Training Time: {training_time:.1f}s\")\n",
    "        print(f\"  Epochs Trained: {fold_result['epochs_trained']}\")\n",
    "    \n",
    "    return cv_results\n",
    "\n",
    "# Run cross validation\n",
    "print(\"Starting K-Fold Cross Validation...\")\n",
    "cv_results = run_cross_validation(fold_information, unified_dataset, epochs=8, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e715cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze Cross-Validation Results\n",
    "def analyze_cv_results(cv_results):\n",
    "    \"\"\"Analyze and visualize cross-validation results\"\"\"\n",
    "    \n",
    "    fold_metrics = cv_results['fold_metrics']\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"CROSS-VALIDATION RESULTS ANALYSIS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Extract metrics\n",
    "    accuracies = [fold['val_accuracy'] for fold in fold_metrics]\n",
    "    losses = [fold['val_loss'] for fold in fold_metrics]\n",
    "    precisions = [fold['val_precision'] for fold in fold_metrics]\n",
    "    recalls = [fold['val_recall'] for fold in fold_metrics]\n",
    "    f1_scores = [fold['val_f1_score'] for fold in fold_metrics]\n",
    "    training_times = cv_results['training_times']\n",
    "    \n",
    "    # Calculate statistics\n",
    "    metrics_stats = {\n",
    "        'accuracy': {\n",
    "            'mean': np.mean(accuracies),\n",
    "            'std': np.std(accuracies),\n",
    "            'min': np.min(accuracies),\n",
    "            'max': np.max(accuracies)\n",
    "        },\n",
    "        'loss': {\n",
    "            'mean': np.mean(losses),\n",
    "            'std': np.std(losses),\n",
    "            'min': np.min(losses),\n",
    "            'max': np.max(losses)\n",
    "        },\n",
    "        'precision': {\n",
    "            'mean': np.mean(precisions),\n",
    "            'std': np.std(precisions),\n",
    "            'min': np.min(precisions),\n",
    "            'max': np.max(precisions)\n",
    "        },\n",
    "        'recall': {\n",
    "            'mean': np.mean(recalls),\n",
    "            'std': np.std(recalls),\n",
    "            'min': np.min(recalls),\n",
    "            'max': np.max(recalls)\n",
    "        },\n",
    "        'f1_score': {\n",
    "            'mean': np.mean(f1_scores),\n",
    "            'std': np.std(f1_scores),\n",
    "            'min': np.min(f1_scores),\n",
    "            'max': np.max(f1_scores)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Print detailed results\n",
    "    print(\"Individual Fold Results:\")\n",
    "    print(\"-\" * 70)\n",
    "    print(f\"{'Fold':<5} {'Accuracy':<10} {'Loss':<10} {'Precision':<11} {'Recall':<10} {'F1-Score':<10} {'Time(s)':<8}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    for i, fold in enumerate(fold_metrics):\n",
    "        print(f\"{fold['fold']:<5} {fold['val_accuracy']:<10.4f} {fold['val_loss']:<10.4f} \"\n",
    "              f\"{fold['val_precision']:<11.4f} {fold['val_recall']:<10.4f} \"\n",
    "              f\"{fold['val_f1_score']:<10.4f} {training_times[i]:<8.1f}\")\n",
    "    \n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(\"\\\\nSummary Statistics:\")\n",
    "    print(\"-\" * 50)\n",
    "    for metric_name, stats in metrics_stats.items():\n",
    "        print(f\"{metric_name.upper():12}:\")\n",
    "        print(f\"  Mean ± Std:  {stats['mean']:.4f} ± {stats['std']:.4f}\")\n",
    "        print(f\"  Range:       [{stats['min']:.4f}, {stats['max']:.4f}]\")\n",
    "        print(f\"  95% CI:      [{stats['mean'] - 1.96*stats['std']:.4f}, {stats['mean'] + 1.96*stats['std']:.4f}]\")\n",
    "        print()\n",
    "    \n",
    "    # Training time statistics\n",
    "    total_time = sum(training_times)\n",
    "    avg_time = np.mean(training_times)\n",
    "    print(f\"TRAINING TIME:\")\n",
    "    print(f\"  Total time:    {total_time:.1f}s ({total_time/60:.1f}m)\")\n",
    "    print(f\"  Average/fold:  {avg_time:.1f}s\")\n",
    "    print(f\"  Time range:    [{min(training_times):.1f}s, {max(training_times):.1f}s]\")\n",
    "    \n",
    "    return metrics_stats\n",
    "\n",
    "# Analyze results\n",
    "metrics_statistics = analyze_cv_results(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a3f9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Cross-Validation Results\n",
    "def plot_cv_results(cv_results, metrics_stats):\n",
    "    \"\"\"Create comprehensive visualizations of CV results\"\"\"\n",
    "    \n",
    "    fold_metrics = cv_results['fold_metrics']\n",
    "    fold_histories = cv_results['fold_histories']\n",
    "    \n",
    "    # Extract data for plotting\n",
    "    folds = [f\"Fold {fold['fold']}\" for fold in fold_metrics]\n",
    "    accuracies = [fold['val_accuracy'] for fold in fold_metrics]\n",
    "    losses = [fold['val_loss'] for fold in fold_metrics]\n",
    "    precisions = [fold['val_precision'] for fold in fold_metrics]\n",
    "    recalls = [fold['val_recall'] for fold in fold_metrics]\n",
    "    f1_scores = [fold['val_f1_score'] for fold in fold_metrics]\n",
    "    \n",
    "    # Create subplot figure\n",
    "    fig = plt.figure(figsize=(20, 15))\n",
    "    \n",
    "    # 1. Bar plot of metrics across folds\n",
    "    ax1 = plt.subplot(3, 3, 1)\n",
    "    x = np.arange(len(folds))\n",
    "    width = 0.15\n",
    "    \n",
    "    ax1.bar(x - 2*width, accuracies, width, label='Accuracy', alpha=0.8, color='blue')\n",
    "    ax1.bar(x - width, precisions, width, label='Precision', alpha=0.8, color='green')\n",
    "    ax1.bar(x, recalls, width, label='Recall', alpha=0.8, color='orange')\n",
    "    ax1.bar(x + width, f1_scores, width, label='F1-Score', alpha=0.8, color='red')\n",
    "    \n",
    "    ax1.set_xlabel('Folds')\n",
    "    ax1.set_ylabel('Score')\n",
    "    ax1.set_title('Metrics Across Folds')\n",
    "    ax1.set_xticks(x)\n",
    "    ax1.set_xticklabels(folds)\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Box plot of metrics\n",
    "    ax2 = plt.subplot(3, 3, 2)\n",
    "    metrics_data = [accuracies, precisions, recalls, f1_scores]\n",
    "    ax2.boxplot(metrics_data, labels=['Accuracy', 'Precision', 'Recall', 'F1-Score'])\n",
    "    ax2.set_title('Metrics Distribution')\n",
    "    ax2.set_ylabel('Score')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Loss across folds\n",
    "    ax3 = plt.subplot(3, 3, 3)\n",
    "    ax3.bar(folds, losses, color='purple', alpha=0.7)\n",
    "    ax3.set_title('Validation Loss Across Folds')\n",
    "    ax3.set_xlabel('Folds')\n",
    "    ax3.set_ylabel('Loss')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Training curves for all folds - Accuracy\n",
    "    ax4 = plt.subplot(3, 3, 4)\n",
    "    colors = ['blue', 'green', 'red', 'purple', 'orange']\n",
    "    for i, history in enumerate(fold_histories):\n",
    "        epochs = range(1, len(history['accuracy']) + 1)\n",
    "        ax4.plot(epochs, history['accuracy'], f'{colors[i]}-', label=f'Fold {i+1} Train', alpha=0.7)\n",
    "        ax4.plot(epochs, history['val_accuracy'], f'{colors[i]}--', label=f'Fold {i+1} Val', alpha=0.7)\n",
    "    ax4.set_title('Training Curves - Accuracy')\n",
    "    ax4.set_xlabel('Epoch')\n",
    "    ax4.set_ylabel('Accuracy')\n",
    "    ax4.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 5. Training curves for all folds - Loss\n",
    "    ax5 = plt.subplot(3, 3, 5)\n",
    "    for i, history in enumerate(fold_histories):\n",
    "        epochs = range(1, len(history['loss']) + 1)\n",
    "        ax5.plot(epochs, history['loss'], f'{colors[i]}-', label=f'Fold {i+1} Train', alpha=0.7)\n",
    "        ax5.plot(epochs, history['val_loss'], f'{colors[i]}--', label=f'Fold {i+1} Val', alpha=0.7)\n",
    "    ax5.set_title('Training Curves - Loss')\n",
    "    ax5.set_xlabel('Epoch')\n",
    "    ax5.set_ylabel('Loss')\n",
    "    ax5.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    ax5.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 6. Mean and standard deviation\n",
    "    ax6 = plt.subplot(3, 3, 6)\n",
    "    metrics_names = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
    "    means = [metrics_stats['accuracy']['mean'], metrics_stats['precision']['mean'], \n",
    "             metrics_stats['recall']['mean'], metrics_stats['f1_score']['mean']]\n",
    "    stds = [metrics_stats['accuracy']['std'], metrics_stats['precision']['std'], \n",
    "            metrics_stats['recall']['std'], metrics_stats['f1_score']['std']]\n",
    "    \n",
    "    ax6.bar(metrics_names, means, yerr=stds, capsize=5, alpha=0.7, color=['blue', 'green', 'orange', 'red'])\n",
    "    ax6.set_title('Mean ± Std of Metrics')\n",
    "    ax6.set_ylabel('Score')\n",
    "    ax6.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 7. Stability plot (coefficient of variation)\n",
    "    ax7 = plt.subplot(3, 3, 7)\n",
    "    cv_coeffs = [std/mean for mean, std in zip(means, stds)]\n",
    "    ax7.bar(metrics_names, cv_coeffs, alpha=0.7, color='purple')\n",
    "    ax7.set_title('Coefficient of Variation (Stability)')\n",
    "    ax7.set_ylabel('CV = Std/Mean')\n",
    "    ax7.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 8. Epochs trained per fold\n",
    "    ax8 = plt.subplot(3, 3, 8)\n",
    "    epochs_trained = [fold['epochs_trained'] for fold in fold_metrics]\n",
    "    ax8.bar(folds, epochs_trained, alpha=0.7, color='brown')\n",
    "    ax8.set_title('Epochs Trained per Fold')\n",
    "    ax8.set_xlabel('Folds')\n",
    "    ax8.set_ylabel('Epochs')\n",
    "    ax8.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 9. Final comparison with confidence intervals\n",
    "    ax9 = plt.subplot(3, 3, 9)\n",
    "    # Calculate 95% confidence intervals\n",
    "    ci_lower = [mean - 1.96*std for mean, std in zip(means, stds)]\n",
    "    ci_upper = [mean + 1.96*std for mean, std in zip(means, stds)]\n",
    "    \n",
    "    ax9.errorbar(range(len(metrics_names)), means, \n",
    "                yerr=[np.array(means) - np.array(ci_lower), np.array(ci_upper) - np.array(means)],\n",
    "                fmt='o', capsize=5, capthick=2, markersize=8)\n",
    "    ax9.set_xticks(range(len(metrics_names)))\n",
    "    ax9.set_xticklabels(metrics_names)\n",
    "    ax9.set_title('95% Confidence Intervals')\n",
    "    ax9.set_ylabel('Score')\n",
    "    ax9.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Create visualizations\n",
    "print(\"Creating comprehensive visualizations...\")\n",
    "plot_cv_results(cv_results, metrics_statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daef784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Cross-Validation Results with Original Model and Save Results\n",
    "def compare_with_original_model(cv_results, original_val_accuracy=None):\n",
    "    \"\"\"Compare CV results with the original single train/val split model\"\"\"\n",
    "    \n",
    "    fold_metrics = cv_results['fold_metrics']\n",
    "    cv_accuracy_mean = np.mean([fold['val_accuracy'] for fold in fold_metrics])\n",
    "    cv_accuracy_std = np.std([fold['val_accuracy'] for fold in fold_metrics])\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"COMPARISON: CROSS-VALIDATION vs SINGLE SPLIT\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    if original_val_accuracy is not None:\n",
    "        print(f\"Original Model (Single Split):\")\n",
    "        print(f\"  Validation Accuracy: {original_val_accuracy:.4f}\")\n",
    "        print()\n",
    "    \n",
    "    print(f\"Cross-Validation Results:\")\n",
    "    print(f\"  Mean Accuracy: {cv_accuracy_mean:.4f} ± {cv_accuracy_std:.4f}\")\n",
    "    print(f\"  Confidence Interval (95%): [{cv_accuracy_mean - 1.96*cv_accuracy_std:.4f}, {cv_accuracy_mean + 1.96*cv_accuracy_std:.4f}]\")\n",
    "    \n",
    "    if original_val_accuracy is not None:\n",
    "        diff = cv_accuracy_mean - original_val_accuracy\n",
    "        print(f\"\\\\nDifference (CV - Original): {diff:+.4f}\")\n",
    "        \n",
    "        if abs(diff) < cv_accuracy_std:\n",
    "            print(\"✅ Results are consistent - difference within 1 standard deviation\")\n",
    "        elif abs(diff) < 2 * cv_accuracy_std:\n",
    "            print(\"⚠️ Moderate difference - within 2 standard deviations\")\n",
    "        else:\n",
    "            print(\"❌ Significant difference - more than 2 standard deviations\")\n",
    "    \n",
    "    print(\"\\\\n\" + \"=\"*70)\n",
    "    print(\"CROSS-VALIDATION BENEFITS:\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"✅ More robust performance estimate\")\n",
    "    print(\"✅ Reduced overfitting to validation set\")\n",
    "    print(\"✅ Better understanding of model variability\")\n",
    "    print(\"✅ More reliable confidence in results\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "# Save cross-validation results\n",
    "def save_cv_results(cv_results, metrics_stats, output_dir=None):\n",
    "    \"\"\"Save cross-validation results to files\"\"\"\n",
    "    \n",
    "    if output_dir is None:\n",
    "        output_dir = os.path.join(os.getcwd(), 'cross_validation_results')\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Save detailed results as JSON\n",
    "    results_to_save = {\n",
    "        'fold_metrics': cv_results['fold_metrics'],\n",
    "        'training_times': cv_results['training_times'],\n",
    "        'summary_statistics': metrics_stats,\n",
    "        'cv_summary': {\n",
    "            'num_folds': len(cv_results['fold_metrics']),\n",
    "            'mean_accuracy': metrics_stats['accuracy']['mean'],\n",
    "            'std_accuracy': metrics_stats['accuracy']['std'],\n",
    "            'mean_f1_score': metrics_stats['f1_score']['mean'],\n",
    "            'std_f1_score': metrics_stats['f1_score']['std'],\n",
    "            'total_training_time': sum(cv_results['training_times'])\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Save as JSON\n",
    "    json_path = os.path.join(output_dir, 'cv_results.json')\n",
    "    with open(json_path, 'w') as f:\n",
    "        json.dump(results_to_save, f, indent=2)\n",
    "    print(f\"✅ CV results saved to: {json_path}\")\n",
    "    \n",
    "    # Save as pickle (preserves all data including models)\n",
    "    pickle_path = os.path.join(output_dir, 'cv_results_complete.pkl')\n",
    "    with open(pickle_path, 'wb') as f:\n",
    "        pickle.dump(cv_results, f)\n",
    "    print(f\"✅ Complete CV results (including models) saved to: {pickle_path}\")\n",
    "    \n",
    "    # Create summary report\n",
    "    report_path = os.path.join(output_dir, 'cv_summary_report.txt')\n",
    "    with open(report_path, 'w') as f:\n",
    "        f.write(\"CROSS-VALIDATION SUMMARY REPORT\\\\n\")\n",
    "        f.write(\"=\"*50 + \"\\\\n\")\n",
    "        f.write(f\"Date: {pd.Timestamp.now()}\\\\n\")\n",
    "        f.write(f\"Number of folds: {len(cv_results['fold_metrics'])}\\\\n\")\n",
    "        f.write(f\"Total samples: {len(unified_dataset)}\\\\n\")\n",
    "        f.write(\"\\\\n\")\n",
    "        \n",
    "        f.write(\"PERFORMANCE METRICS:\\\\n\")\n",
    "        f.write(\"-\" * 30 + \"\\\\n\")\n",
    "        for metric_name, stats in metrics_stats.items():\n",
    "            f.write(f\"{metric_name.upper()}:\\\\n\")\n",
    "            f.write(f\"  Mean: {stats['mean']:.4f}\\\\n\")\n",
    "            f.write(f\"  Std:  {stats['std']:.4f}\\\\n\")\n",
    "            f.write(f\"  95% CI: [{stats['mean'] - 1.96*stats['std']:.4f}, {stats['mean'] + 1.96*stats['std']:.4f}]\\\\n\")\n",
    "            f.write(\"\\\\n\")\n",
    "        \n",
    "        f.write(\"INDIVIDUAL FOLD RESULTS:\\\\n\")\n",
    "        f.write(\"-\" * 30 + \"\\\\n\")\n",
    "        for fold in cv_results['fold_metrics']:\n",
    "            f.write(f\"Fold {fold['fold']}: Acc={fold['val_accuracy']:.4f}, \"\n",
    "                   f\"F1={fold['val_f1_score']:.4f}, Loss={fold['val_loss']:.4f}\\\\n\")\n",
    "    \n",
    "    print(f\"✅ Summary report saved to: {report_path}\")\n",
    "    \n",
    "    return output_dir\n",
    "\n",
    "# Compare results (use the validation accuracy from our previous single model training if available)\n",
    "# You can update this with the actual value from your previous training\n",
    "original_accuracy = val_accuracy if 'val_accuracy' in globals() else None\n",
    "compare_with_original_model(cv_results, original_accuracy)\n",
    "\n",
    "# Save results\n",
    "print(\"\\\\nSaving cross-validation results...\")\n",
    "cv_output_dir = save_cv_results(cv_results, metrics_statistics)\n",
    "\n",
    "print(f\"\\\\n📊 Cross-validation complete! Results saved to: {cv_output_dir}\")\n",
    "\n",
    "# Final summary\n",
    "print(\"\\\\n\" + \"=\"*70)\n",
    "print(\"🎉 STRATIFIED K-FOLD CROSS-VALIDATION COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"✅ Trained and evaluated {len(cv_results['fold_metrics'])} models\")\n",
    "print(f\"✅ Mean validation accuracy: {metrics_statistics['accuracy']['mean']:.4f} ± {metrics_statistics['accuracy']['std']:.4f}\")\n",
    "print(f\"✅ Mean F1-score: {metrics_statistics['f1_score']['mean']:.4f} ± {metrics_statistics['f1_score']['std']:.4f}\")\n",
    "print(f\"✅ Total training time: {sum(cv_results['training_times']):.1f}s ({sum(cv_results['training_times'])/60:.1f}m)\")\n",
    "print(f\"✅ All results and models saved for future analysis\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xaropinho",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
