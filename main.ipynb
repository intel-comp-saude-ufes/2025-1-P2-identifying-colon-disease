{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fd0ad0b",
   "metadata": {},
   "source": [
    "# Baixando dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27e54947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/francismon/curated-colon-dataset-for-deep-learning?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.41G/1.41G [02:38<00:00, 9.55MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset downloaded/cached at: C:\\Users\\mathe\\.cache\\kagglehub\\datasets\\francismon\\curated-colon-dataset-for-deep-learning\\versions\\1\n",
      "Dataset path: C:\\Users\\mathe\\.cache\\kagglehub\\datasets\\francismon\\curated-colon-dataset-for-deep-learning\\versions\\1\n",
      "Number of test images: 200\n",
      "Number of train images: 3200\n",
      "Sample test files: ['test_normal_ (1).jpg', 'test_normal_ (10).jpg', 'test_normal_ (100).jpg', 'test_normal_ (101).jpg', 'test_normal_ (102).jpg']\n",
      "Sample train files: [('train_normal_ (1).jpg', 0), ('train_normal_ (10).jpg', 0), ('train_normal_ (100).jpg', 0), ('train_normal_ (101).jpg', 0), ('train_normal_ (102).jpg', 0)]\n"
     ]
    }
   ],
   "source": [
    "# Import the DataLoader class from the get_data_from_db module\n",
    "from get_data_from_db import DataLoader\n",
    "\n",
    "# Initialize the DataLoader\n",
    "data_loader = DataLoader()\n",
    "\n",
    "# Get the dataset path\n",
    "path = data_loader.path\n",
    "print(f\"Dataset path: {path}\")\n",
    "\n",
    "# Get test and train data\n",
    "test_data = data_loader.get_test_data()\n",
    "train_data = data_loader.get_train_data()\n",
    "\n",
    "print(f\"Number of test images: {len(test_data)}\")\n",
    "print(f\"Number of train images: {len(train_data)}\")\n",
    "print(f\"Sample test files: {test_data[:5] if len(test_data) > 5 else test_data}\")\n",
    "print(f\"Sample train files: {train_data[:5] if len(train_data) > 5 else train_data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e597427a",
   "metadata": {},
   "source": [
    "Os arquivos já estavam separados em treino e teste"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccb9228",
   "metadata": {},
   "source": [
    "Obtendo os arquivos de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0989c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Summary:\n",
      "Test Normal: 200 images\n",
      "Train Normal: 800 images\n",
      "Train Ulcerative Colitis: 800 images\n",
      "Train Polyps: 800 images\n",
      "Train Esophagitis: 800 images\n",
      "\n",
      "Total Test Images: 200\n",
      "Total Train Images: 3200\n",
      "Total Dataset: 3400 images\n"
     ]
    }
   ],
   "source": [
    "# Using the DataLoader to get all category paths and files\n",
    "import os\n",
    "\n",
    "# Get all test categories (normal)\n",
    "test_normal_path = os.path.join(path, \"test\", \"0_normal\")\n",
    "test_normal_files = os.listdir(test_normal_path)\n",
    "\n",
    "# Get all train categories\n",
    "train_normal_path = os.path.join(path, \"train\", \"0_normal\")\n",
    "train_normal_files = os.listdir(train_normal_path)\n",
    "\n",
    "train_ulcerative_colitis_path = os.path.join(path, \"train\", \"1_ulcerative_colitis\")\n",
    "train_ulcerative_colitis_files = os.listdir(train_ulcerative_colitis_path)\n",
    "\n",
    "train_polyps_path = os.path.join(path, \"train\", \"2_polyps\")\n",
    "train_polyps_files = os.listdir(train_polyps_path)\n",
    "\n",
    "train_esophagitis_path = os.path.join(path, \"train\", \"3_esophagitis\")\n",
    "train_esophagitis_files = os.listdir(train_esophagitis_path)\n",
    "\n",
    "# Print summary of all categories\n",
    "print(\"Dataset Summary:\")\n",
    "print(f\"Test Normal: {len(test_normal_files)} images\")\n",
    "print(f\"Train Normal: {len(train_normal_files)} images\")\n",
    "print(f\"Train Ulcerative Colitis: {len(train_ulcerative_colitis_files)} images\")\n",
    "print(f\"Train Polyps: {len(train_polyps_files)} images\")\n",
    "print(f\"Train Esophagitis: {len(train_esophagitis_files)} images\")\n",
    "\n",
    "# Total counts\n",
    "total_test = len(test_normal_files)\n",
    "total_train = len(train_normal_files) + len(train_ulcerative_colitis_files) + len(train_polyps_files) + len(train_esophagitis_files)\n",
    "print(f\"\\nTotal Test Images: {total_test}\")\n",
    "print(f\"Total Train Images: {total_train}\")\n",
    "print(f\"Total Dataset: {total_test + total_train} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b245614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset downloaded/cached at: C:\\Users\\mathe\\.cache\\kagglehub\\datasets\\francismon\\curated-colon-dataset-for-deep-learning\\versions\\1\n",
      "Complete Dataset Counts:\n",
      "  test_normal: 200 images\n",
      "  train_normal: 800 images\n",
      "  train_ulcerative_colitis: 800 images\n",
      "  train_polyps: 800 images\n",
      "  train_esophagitis: 800 images\n",
      "  val_normal: 500 images\n",
      "  val_ulcerative_colitis: 500 images\n",
      "  val_polyps: 500 images\n",
      "  val_esophagitis: 500 images\n",
      "\n",
      "Dataset Split Summary:\n",
      "  Training: 3200 images\n",
      "  Validation: 2000 images\n",
      "  Testing: 200 images\n",
      "  Total: 5400 images\n",
      "\n",
      "Validation data categories: ['normal', 'ulcerative_colitis', 'polyps', 'esophagitis']\n",
      "Total validation samples with labels: 2000\n",
      "Sample validation data with labels:\n",
      "  val_normal_ (1).jpg -> normal (label: 0)\n",
      "  val_normal_ (10).jpg -> normal (label: 0)\n",
      "  val_normal_ (100).jpg -> normal (label: 0)\n",
      "  val_normal_ (101).jpg -> normal (label: 0)\n",
      "  val_normal_ (102).jpg -> normal (label: 0)\n",
      "\n",
      "Category Distribution:\n",
      "  NORMAL:\n",
      "    Train: 800, Val: 500, Test: 200\n",
      "    Total: 1500\n",
      "  ULCERATIVE_COLITIS:\n",
      "    Train: 800, Val: 500, Test: 0\n",
      "    Total: 1300\n",
      "  POLYPS:\n",
      "    Train: 800, Val: 500, Test: 0\n",
      "    Total: 1300\n",
      "  ESOPHAGITIS:\n",
      "    Train: 800, Val: 500, Test: 0\n",
      "    Total: 1300\n"
     ]
    }
   ],
   "source": [
    "# Complete dataset analysis including validation data\n",
    "import importlib\n",
    "importlib.reload(get_data_from_db)\n",
    "from get_data_from_db import DataLoader\n",
    "\n",
    "# Create a new DataLoader instance with enhanced features\n",
    "enhanced_loader = DataLoader()\n",
    "\n",
    "# Get all category counts including validation\n",
    "counts = enhanced_loader.get_category_counts()\n",
    "print(\"Complete Dataset Counts:\")\n",
    "for category, count in counts.items():\n",
    "    print(f\"  {category}: {count} images\")\n",
    "\n",
    "# Calculate totals by split\n",
    "test_total = counts['test_normal']\n",
    "train_total = counts['train_normal'] + counts['train_ulcerative_colitis'] + counts['train_polyps'] + counts['train_esophagitis']\n",
    "val_total = counts['val_normal'] + counts['val_ulcerative_colitis'] + counts['val_polyps'] + counts['val_esophagitis']\n",
    "total_images = test_total + train_total + val_total\n",
    "\n",
    "print(f\"\\nDataset Split Summary:\")\n",
    "print(f\"  Training: {train_total} images\")\n",
    "print(f\"  Validation: {val_total} images\")\n",
    "print(f\"  Testing: {test_total} images\")\n",
    "print(f\"  Total: {total_images} images\")\n",
    "\n",
    "# Get validation data organized by category\n",
    "validation_by_category = enhanced_loader.get_validation_data()\n",
    "print(f\"\\nValidation data categories: {list(validation_by_category.keys())}\")\n",
    "\n",
    "# Get validation data with labels\n",
    "validation_with_labels = enhanced_loader.get_validation_data_with_labels()\n",
    "print(f\"Total validation samples with labels: {len(validation_with_labels)}\")\n",
    "print(\"Sample validation data with labels:\")\n",
    "category_names = ['normal', 'ulcerative_colitis', 'polyps', 'esophagitis']\n",
    "for i in range(min(5, len(validation_with_labels))):\n",
    "    filename, label = validation_with_labels[i]\n",
    "    print(f\"  {filename} -> {category_names[label]} (label: {label})\")\n",
    "\n",
    "# Show distribution across categories\n",
    "print(f\"\\nCategory Distribution:\")\n",
    "for i, category in enumerate(category_names):\n",
    "    train_count = counts[f'train_{category}']\n",
    "    val_count = counts[f'val_{category}']\n",
    "    test_count = counts['test_normal'] if category == 'normal' else 0\n",
    "    print(f\"  {category.upper()}:\")\n",
    "    print(f\"    Train: {train_count}, Val: {val_count}, Test: {test_count}\")\n",
    "    print(f\"    Total: {train_count + val_count + test_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6862ea7",
   "metadata": {},
   "source": [
    "# Análise Completa do Dataset\n",
    "\n",
    "O dataset está organizado em três divisões:\n",
    "\n",
    "## Estrutura do Dataset:\n",
    "- **Treino (train/)**: 3.200 imagens (800 por categoria)\n",
    "- **Validação (val/)**: 2.000 imagens (500 por categoria)  \n",
    "- **Teste (test/)**: 200 imagens (apenas categoria normal)\n",
    "\n",
    "## Categorias:\n",
    "1. **Normal (0)**: Imagens normais do cólon\n",
    "2. **Ulcerative Colitis (1)**: Colite ulcerativa\n",
    "3. **Polyps (2)**: Pólipos\n",
    "4. **Esophagitis (3)**: Esofagite\n",
    "\n",
    "## Total: 5.400 imagens\n",
    "\n",
    "**Nota**: O conjunto de teste contém apenas imagens da categoria \"normal\", enquanto treino e validação contêm todas as 4 categorias balanceadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6dfbe173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for Machine Learning:\n",
      "Training samples: 3200 (with labels)\n",
      "Validation samples: 2000 (with labels)\n",
      "Test samples: 200 (normal only)\n",
      "\n",
      "Label distribution in training:\n",
      "  Label 0 (normal): 800 samples\n",
      "  Label 1 (ulcerative_colitis): 800 samples\n",
      "  Label 2 (polyps): 800 samples\n",
      "  Label 3 (esophagitis): 800 samples\n",
      "\n",
      "Label distribution in validation:\n",
      "  Label 0 (normal): 500 samples\n",
      "  Label 1 (ulcerative_colitis): 500 samples\n",
      "  Label 2 (polyps): 500 samples\n",
      "  Label 3 (esophagitis): 500 samples\n",
      "\n",
      "Example file paths for 'normal' category:\n",
      "  Train path: C:\\Users\\mathe\\.cache\\kagglehub\\datasets\\francismon\\curated-colon-dataset-for-deep-learning\\versions\\1\\train\\0_normal\n",
      "  Validation path: C:\\Users\\mathe\\.cache\\kagglehub\\datasets\\francismon\\curated-colon-dataset-for-deep-learning\\versions\\1\\val\\0_normal\n",
      "  Sample files: ['train_normal_ (1).jpg', 'train_normal_ (10).jpg', 'train_normal_ (100).jpg'] (train), ['val_normal_ (1).jpg', 'val_normal_ (10).jpg', 'val_normal_ (100).jpg'] (val)\n"
     ]
    }
   ],
   "source": [
    "# Example: How to use the DataLoader for machine learning workflows\n",
    "import numpy as np\n",
    "\n",
    "# Get all data splits with labels\n",
    "train_data_with_labels = enhanced_loader.get_train_data()\n",
    "val_data_with_labels = enhanced_loader.get_validation_data_with_labels()\n",
    "test_data_files = enhanced_loader.get_test_data()  # Only normal images\n",
    "\n",
    "print(\"Data for Machine Learning:\")\n",
    "print(f\"Training samples: {len(train_data_with_labels)} (with labels)\")\n",
    "print(f\"Validation samples: {len(val_data_with_labels)} (with labels)\")\n",
    "print(f\"Test samples: {len(test_data_files)} (normal only)\")\n",
    "\n",
    "# Example: Extract labels for analysis\n",
    "train_labels = [label for _, label in train_data_with_labels]\n",
    "val_labels = [label for _, label in val_data_with_labels]\n",
    "\n",
    "print(f\"\\nLabel distribution in training:\")\n",
    "unique_labels, train_counts = np.unique(train_labels, return_counts=True)\n",
    "for label, count in zip(unique_labels, train_counts):\n",
    "    print(f\"  Label {label} ({category_names[label]}): {count} samples\")\n",
    "\n",
    "print(f\"\\nLabel distribution in validation:\")\n",
    "unique_labels, val_counts = np.unique(val_labels, return_counts=True)\n",
    "for label, count in zip(unique_labels, val_counts):\n",
    "    print(f\"  Label {label} ({category_names[label]}): {count} samples\")\n",
    "\n",
    "# Example: Get full file paths for a specific category\n",
    "normal_train_files = enhanced_loader.get_train_data_by_category()['normal']\n",
    "normal_val_files = enhanced_loader.get_validation_data()['normal']\n",
    "\n",
    "print(f\"\\nExample file paths for 'normal' category:\")\n",
    "print(f\"  Train path: {enhanced_loader.train_normal_path}\")\n",
    "print(f\"  Validation path: {enhanced_loader.validation_normal_path}\")\n",
    "print(f\"  Sample files: {normal_train_files[:3]} (train), {normal_val_files[:3]} (val)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xaropinho",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
